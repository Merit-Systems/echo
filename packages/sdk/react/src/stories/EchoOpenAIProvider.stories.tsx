import type { Meta, StoryObj } from '@storybook/react-vite';
import React, { useState } from 'react';
import { useEchoOpenAI } from '../hooks/useEchoOpenAI';
import { MockEchoProvider, mockStates } from './MockEchoProvider';
import { EchoContextValue } from '../context';

// Create a wrapper component for the hook stories
function UseEchoOpenAIDemo() {
  return <div>Hook Demo Component</div>;
}

const meta: Meta<typeof UseEchoOpenAIDemo> = {
  title: 'Echo SDK/useEchoOpenAI',
  component: UseEchoOpenAIDemo,
  parameters: {
    docs: {
      description: {
        component:
          "The useEchoOpenAI hook provides an OpenAI client instance that is automatically authenticated with your Echo token. This enables you to use the OpenAI SDK with Echo's proxy service without needing a provider component.",
      },
    },
  },
  tags: ['autodocs'],
};

export default meta;
type Story = StoryObj<typeof meta>;

// Demo component that uses the useEchoOpenAI hook
function OpenAIDemo() {
  const { openai, isReady, error, isLoading } = useEchoOpenAI({
    baseURL: 'https://echo.router.merit.systems',
    enabled: true,
  });

  const [prompt, setPrompt] = useState('Tell me a joke about programming');
  const [response, setResponse] = useState<string>('');
  const [isGenerating, setIsGenerating] = useState(false);
  const [useStreaming, setUseStreaming] = useState(true);
  const [conversationHistory, setConversationHistory] = useState<
    Array<{ role: string; content: string }>
  >([]);

  // Real OpenAI SDK usage patterns (this would work with actual OpenAI when the package is installed)
  const generateMessage = async () => {
    if (!openai || !isReady) {
      // In Storybook, show what the real implementation would look like
      setIsGenerating(true);
      setResponse('');

      // Simulate the real API call with realistic responses
      await new Promise(resolve => setTimeout(resolve, 500));

      let mockContent = '';
      if (prompt.toLowerCase().includes('joke')) {
        mockContent =
          'Why do programmers prefer dark mode? Because light attracts bugs! üêõ';
      } else if (prompt.toLowerCase().includes('react')) {
        mockContent =
          'React is a JavaScript library for building user interfaces. It uses a component-based architecture and a virtual DOM for efficient updates. Key concepts include JSX, props, state, and hooks.';
      } else if (prompt.toLowerCase().includes('error')) {
        setResponse('Error: Simulated API error - rate limit exceeded');
        setIsGenerating(false);
        return;
      } else {
        mockContent = `I understand you're asking about: "${prompt}"\n\nThis is a mock response showing how the OpenAI SDK would work with Echo authentication. In a real application, this would be generated by the AI model.`;
      }

      if (useStreaming) {
        // Simulate streaming response
        const words = mockContent.split(' ');
        let fullResponse = '';
        for (let i = 0; i < words.length; i++) {
          await new Promise(resolve => setTimeout(resolve, 50));
          fullResponse += (i > 0 ? ' ' : '') + words[i];
          setResponse(fullResponse);
        }
        setConversationHistory([
          ...conversationHistory,
          { role: 'user', content: prompt },
          { role: 'assistant', content: fullResponse },
        ]);
      } else {
        setResponse(mockContent);
        setConversationHistory([
          ...conversationHistory,
          { role: 'user', content: prompt },
          { role: 'assistant', content: mockContent },
        ]);
      }

      setIsGenerating(false);
      return;
    }

    // This is the actual OpenAI SDK usage pattern that would work in production
    setIsGenerating(true);
    setResponse('');

    try {
      const messages = [
        ...conversationHistory,
        { role: 'user', content: prompt },
      ];

      if (useStreaming) {
        // Real streaming implementation
        const stream = await openai.chat.completions.create({
          model: 'gpt-3.5-turbo',
          messages: messages as Array<{
            role: 'user' | 'assistant' | 'system';
            content: string;
          }>,
          stream: true,
          max_tokens: 150,
        });

        let fullResponse = '';
        for await (const chunk of stream as AsyncIterable<{
          choices: Array<{ delta?: { content?: string } }>;
        }>) {
          const content = chunk.choices[0]?.delta?.content || '';
          fullResponse += content;
          setResponse(fullResponse);
        }

        setConversationHistory([
          ...messages,
          { role: 'assistant', content: fullResponse },
        ]);
      } else {
        // Real non-streaming implementation
        const completion = await openai.chat.completions.create({
          model: 'gpt-3.5-turbo',
          messages: messages as Array<{
            role: 'user' | 'assistant' | 'system';
            content: string;
          }>,
          max_tokens: 150,
        });

        const content = completion.choices[0]?.message?.content || '';
        setResponse(content);
        setConversationHistory([...messages, { role: 'assistant', content }]);
      }
    } catch (err) {
      const errorMessage =
        err && typeof err === 'object' && 'message' in err
          ? (err as Error).message
          : String(err);
      setResponse(`Error: ${errorMessage}`);
    } finally {
      setIsGenerating(false);
    }
  };

  const clearConversation = () => {
    setConversationHistory([]);
    setResponse('');
    setPrompt('Tell me a joke about programming');
  };

  return (
    <div
      style={{
        padding: '20px',
        fontFamily: 'Arial, sans-serif',
        maxWidth: '800px',
      }}
    >
      <h3>useEchoOpenAI Hook Demo</h3>

      <div
        style={{
          background: '#f5f5f5',
          padding: '15px',
          borderRadius: '8px',
          marginBottom: '20px',
        }}
      >
        <p>
          <strong>Hook Loading:</strong> {isLoading ? 'Yes' : 'No'}
        </p>
        <p>
          <strong>OpenAI Client Ready:</strong> {isReady ? 'Yes' : 'No'}
        </p>
        <p>
          <strong>Error:</strong> {error || 'None'}
        </p>
        <p>
          <strong>Status:</strong> {isGenerating ? 'Generating...' : 'Ready'}
        </p>
        <p>
          <strong>Mode:</strong>{' '}
          {openai ? 'Real OpenAI SDK' : 'Mock (Storybook)'}
        </p>
      </div>

      <div style={{ marginBottom: '20px' }}>
        <label
          style={{ display: 'block', marginBottom: '8px', fontWeight: 'bold' }}
        >
          Settings:
        </label>
        <div style={{ display: 'flex', gap: '20px', alignItems: 'center' }}>
          <label style={{ display: 'flex', alignItems: 'center', gap: '8px' }}>
            <input
              type="checkbox"
              checked={useStreaming}
              onChange={e => setUseStreaming(e.target.checked)}
            />
            Use Streaming
          </label>
          <button
            onClick={clearConversation}
            style={{
              padding: '8px 16px',
              backgroundColor: '#666',
              color: 'white',
              border: 'none',
              borderRadius: '4px',
              fontSize: '14px',
              cursor: 'pointer',
            }}
          >
            Clear History
          </button>
        </div>
      </div>

      {conversationHistory.length > 0 && (
        <div style={{ marginBottom: '20px' }}>
          <label
            style={{
              display: 'block',
              marginBottom: '8px',
              fontWeight: 'bold',
            }}
          >
            Conversation History:
          </label>
          <div
            style={{
              background: '#f9f9f9',
              border: '1px solid #ddd',
              borderRadius: '4px',
              padding: '12px',
              maxHeight: '200px',
              overflowY: 'auto',
            }}
          >
            {conversationHistory.map((msg, index) => (
              <div key={index} style={{ marginBottom: '8px' }}>
                <strong>{msg.role === 'user' ? 'You:' : 'Assistant:'}</strong>
                <div
                  style={{
                    marginLeft: '10px',
                    whiteSpace: 'pre-wrap',
                    fontSize: '14px',
                  }}
                >
                  {msg.content}
                </div>
              </div>
            ))}
          </div>
        </div>
      )}

      <div style={{ marginBottom: '20px' }}>
        <label
          style={{ display: 'block', marginBottom: '8px', fontWeight: 'bold' }}
        >
          Prompt:
        </label>
        <textarea
          value={prompt}
          onChange={e => setPrompt(e.target.value)}
          placeholder="Enter your prompt here... Try: 'joke', 'react', or 'error'"
          style={{
            width: '100%',
            height: '80px',
            padding: '12px',
            border: '1px solid #ddd',
            borderRadius: '4px',
            fontSize: '14px',
            fontFamily: 'Arial, sans-serif',
            resize: 'vertical',
          }}
        />
      </div>

      <button
        onClick={generateMessage}
        disabled={isGenerating || !prompt.trim()}
        style={{
          padding: '12px 24px',
          backgroundColor: !isGenerating ? '#0066cc' : '#ccc',
          color: 'white',
          border: 'none',
          borderRadius: '4px',
          fontSize: '16px',
          fontWeight: 'bold',
          cursor: !isGenerating ? 'pointer' : 'not-allowed',
          marginBottom: '20px',
        }}
      >
        {isGenerating ? 'Generating...' : 'Generate Response'}
      </button>

      <div>
        <label
          style={{ display: 'block', marginBottom: '8px', fontWeight: 'bold' }}
        >
          Current Response:
        </label>
        <div
          style={{
            background: '#f9f9f9',
            border: '1px solid #ddd',
            borderRadius: '4px',
            padding: '12px',
            minHeight: '100px',
            fontSize: '14px',
            lineHeight: '1.5',
            whiteSpace: 'pre-wrap',
          }}
        >
          {response || 'Response will appear here...'}
        </div>
      </div>

      <div
        style={{
          marginTop: '20px',
          padding: '15px',
          background: '#e8f4f8',
          borderRadius: '8px',
          fontSize: '14px',
        }}
      >
        <strong>Code Example:</strong>
        <pre
          style={{
            marginTop: '10px',
            background: '#f0f0f0',
            padding: '10px',
            borderRadius: '4px',
            fontSize: '12px',
          }}
        >
          {`// Real usage in your app:
const { openai, isReady, error, isLoading } = useEchoOpenAI({
  baseURL: 'https://echo.router.merit.systems', // Optional
  enabled: true, // Optional
});

const generateResponse = async () => {
  if (!openai || !isReady) return;
  
  const completion = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [{ role: 'user', content: prompt }],
    stream: ${useStreaming},
    max_tokens: 150,
  });
  
  ${
    useStreaming
      ? `// Handle streaming response
  for await (const chunk of completion) {
    const content = chunk.choices[0]?.delta?.content || '';
    // Update UI with streaming content
  }`
      : `// Handle regular response
  const content = completion.choices[0]?.message?.content;
  // Update UI with complete response`
  }
};`}
        </pre>
      </div>
    </div>
  );
}

// Template component that wraps the demo with only the Echo provider
function Template({ mockState }: { mockState?: Partial<EchoContextValue> }) {
  return (
    <MockEchoProvider mockState={mockState || {}}>
      <OpenAIDemo />
    </MockEchoProvider>
  );
}

export const Default: Story = {
  render: () => <Template mockState={mockStates.authenticated} />,
};

export const Loading: Story = {
  render: () => <Template mockState={mockStates.loading} />,
};

export const Unauthenticated: Story = {
  render: () => <Template mockState={mockStates.unauthenticated} />,
};

export const Error: Story = {
  render: () => <Template mockState={mockStates.error} />,
};

export const LowBalance: Story = {
  render: () => <Template mockState={mockStates.lowBalance} />,
};

export const OpenAINotInstalled: Story = {
  render: () => {
    // Mock the error state that would occur when OpenAI package is not installed
    const mockStateWithError = {
      ...mockStates.authenticated,
      // This simulates the error state that the real useEchoOpenAI hook would have
    };

    return (
      <MockEchoProvider mockState={mockStateWithError}>
        <div style={{ padding: '20px', fontFamily: 'Arial, sans-serif' }}>
          <h3>OpenAI Package Not Found Scenario</h3>

          <div
            style={{
              background: '#fee',
              padding: '15px',
              borderRadius: '8px',
              border: '1px solid #fcc',
              marginBottom: '20px',
            }}
          >
            <p style={{ color: '#c33', margin: '0' }}>
              <strong>Error:</strong> OpenAI package not found. Please install
              it with: pnpm add openai
            </p>
          </div>

          <div
            style={{
              background: '#fff3cd',
              padding: '15px',
              borderRadius: '8px',
              border: '1px solid #ffeaa7',
              marginBottom: '20px',
            }}
          >
            <p style={{ color: '#856404', margin: '0' }}>
              <strong>What happens:</strong> The useEchoOpenAI hook gracefully
              handles missing dependencies by showing a helpful error message
              instead of crashing your app.
            </p>
          </div>

          <div
            style={{
              background: '#f0f0f0',
              padding: '15px',
              borderRadius: '8px',
            }}
          >
            <p style={{ marginBottom: '10px', fontWeight: 'bold' }}>
              To fix this issue:
            </p>
            <ol style={{ marginBottom: '10px' }}>
              <li>
                Install the OpenAI package: <code>pnpm add openai</code>
              </li>
              <li>
                The useEchoOpenAI hook will automatically detect it and create a
                client
              </li>
              <li>Your app will then be able to make LLM calls through Echo</li>
            </ol>

            <p style={{ marginBottom: '10px', fontWeight: 'bold' }}>
              Code example:
            </p>
            <pre
              style={{
                background: '#e8e8e8',
                padding: '10px',
                borderRadius: '4px',
                fontSize: '12px',
              }}
            >
              {`// In your component:
const { openai, isReady, error, isLoading } = useEchoOpenAI();

if (isLoading) {
  return <div>Loading OpenAI client...</div>;
}

if (error) {
  return <div>Error: {error}</div>;
}

if (!isReady) {
  return <div>OpenAI client not ready...</div>;
}

// Now you can use the openai client safely`}
            </pre>
          </div>
        </div>
      </MockEchoProvider>
    );
  },
};
